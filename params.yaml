train:
  batch_size: 128
  hidden_units: 128
  dropout: 0.2
  num_epochs: 10
  lr: 0.003
  conv_activation: relu
